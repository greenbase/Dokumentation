\chapter{Datapreparation}
\label{ch:datapreparation}

Die rohe Datensatz enthält 200 Datenpunkte, die jeweils einen Öffungs/Schließ-Zyklus darstellen. Je die Hälfte davon gehören der positiven und der negativen Kategorie an; sind also mit beschädigten bzw. unbeschädigten Umlenkrollen aufgezeichnet worden.

Für jeden Zyklus wurde dessen Dauer mitgeschrieben; sprich die Zeit vom Beginn des Öffnungsvorgangs bis zur erneuten Aktivierung des Magnetschalters, der eine geschlossene Tür signalisiert. 
Weiterhin wurden alle 50 Millisekunden Beschleunigungswerte und Rotationsgeschwindigkeiten entlange aller drei Raumrichtungen aufgezeichnet. Insgesamt also sechs Messwerte.
Damit verfügt der rohe Datensatz über 1441 Merkmale; 240 je Messwert zuzüglich der Dauer.

WARUM MACHT ES SINN DEN DATENSATZ ZUSAMMENZUFASSENß
Relativ zu der Anzahl an Merkmalen weisen die Entscheidungsbäume aller Modelle wenige Knoten auf. Würde der rohe Datensatz für die Modellierung verwendet werden hätte das eine Reihe unerwünschter Folgen:
\begin{itemize}
    \item Das Modell vom Typ eines einfachen Entscheidungsbaum würde nur einen sehr kleinen Anteil der Merkmale verwenden, die einen Datenpunkt beschreiben. Da für die einzelnen Messgrößen (Beschleunigung und Rotationgeschw.) 240 Werte je Zyklus aufgenommen werden, ist die Bedeutung eines einzelnen Wertes in Frage zu stellen. Besser wäre es beschreibende Charakteristika der gemessenen Messgrößenverteilungen zu bestimmen. Diese würden die Eigenschaften eines Datenpunktes besser verallgemeinern, was in der Regel eine bessere Modellqualität erwarten lässt. Gleichzeitig würde sich durch das Zusammenfassen der Wertereihen der Messgrößen die Anzahl verfügbaren Merkmale reduzieren, sodass das Modell insgesamt auf eine größere Informationsmenge zugreifen kann. Die Informationsdichte wurde erhöht.
    \item Gradient Boosted Trees haben die gleiche Schwachstelle wie einzelne Bäume, weil alle Bäume in der Reihe die selben Merkmale verwenden. \todo{Prüfe: ist das richtig?}
\end{itemize}

Random Forests können auch aus hochdimensionalen Datensätzen viele Informationen ziehen, weil jeder Baum in einem random Forest potentiell andere Merkmale verwenden kann und die Vorhersage aus allen Bäumen gemittelt wird. Wird nun statt einem detailierten ein beschreibender Datensatz verwendet kann ein Random Forest dennoch ausreichend gute Egebnisse erzielen, weil kein nennenswerter Informationsverlust auftritt. Im beschreibenden Datensatz sind schließlich die Eigenschaften der Messwertverteilungen enthalten und der Random Forst kann selbst bei einer maximalen Baumtiefe von nur einem Knoten so viele Merkmale einbeziehen, wie sie der Anzahl an Bäumen entspricht. 

Es ist also sinnvoll einen statischtisch desrbtiven Datensatz für die Modellierungen zu verwenden.

WIE SIEHT DER BESCHREIBENDE DATENSATZ AUS?
\section{Statischtisch deskriptiver Datensatz}
\label{sec:deskriptiver datensatz}
Da je Messgröße und Zyklus 240 Werte aufgenommen werden und jeder Wert als Merkmal hinterlegt ist, fällt dem einzelnen Wert eine sehr geringe Bedeutung zu. Aussagen über den gesamten Zyklus sollten deswegen besser auf Werte gestützt werden, die die Verteilung der Messwerte beschrieben. 

Für jeden der sechs Messgrößen werden folgende beschreibenden statischtischen Eigenschaften herangezogen, um deren Verteilung zu beschreiben und somit eine höhere Informationsdichte für die Datenpunkte zu erreichen.

Für eine Messgröße werden die Maximal- und Minimalwerte gesammelt. Für die Bewertung eines Zykluses bzw. für die Vorhersage ob eine Umlenkrolle beschädigt ist oder nicht, sind diese aussagekräftig. Extremwerte treten üblicher weise bei Anfahrten und Stoppbewegungen auf. Entscheiden für die Vorhersage ist jedoch ob sich die Extremwerte bei intakten und beschädigten Umlenkrollen signifikant unterscheiden. 
Durch die Beschädigungen sind größere Stoßbelastungen von der Rolle auf dessen Aufhängung zu erwarten, weil die Auflagefläche der Rolle während dess Umlaufen durch die Kerben unterbrochen wird. Durch die Stopbelastung wird das System zu größeren Schwingungen angeregt. Da der Zusammenhang zwischen Anregungskraft und Schwingungsamplitude linear ist, ist bei ausreichend größeren Stoßbelastungen eine größere Amplitude des Gestells zu erwarten. Die Eigenfrequenz bleibt schließlich konstant. Mit konstanter Eigenfrequenz und größerer Amplitude folgt, dass sich die Extremwerte der Beschleunigung weiter vom Mittelwert entfernen. Gleiches gilt für die Rotationsgeschwindigkeiten. Die maximalen und minimalen Werte einer Messgröße sind also gute Indikatoren für eine beschädigte Umlenkrolle.

Die Aussagekraft der Minimal- und Maximalwerte lässt sich durch die Einbeziehung des Median weiter untermauern. Er unterliegt den gleichen Änderungen wie oben beschrieben. Wenn durch die beschädigte Rolle im Mittel größere Kräfte auftreten, sollten auch die durchschnittlichen Beschleunigungen sich entsprechend ändern. STIMMT NICHT: positive und negative Werte verteilen sich um den Median. Der Median sollte sich kaum ändern.
Der Grund warum der Median gewählt wurde ist der, dass er ein besseren Bild von den Verteilungen vermittelt als der Durchschnitt. Er wird nicht entscheidend durch die Extremwerte beeinflusst. Er soll die Werte, die nicht zu den Extremwerten gehören gut beschreiben. Die Extremwerte wurden ja bereits durch eigene Merkmale berücksichtigt und es daher deren Informationen soweit möglich nicht in andere merkmale überführt werden.

Standardabweichung
Ein weiteres Merkmal, das für die Unterscheidung zwischen den Kategorien hilfreich sein kann ist die Standardabweichung. Auch sie wird für die Messreihe jeder Messgröße bestimmt. 

Aufteilung des Datensatzes
Der Datensatz wird in Trainings- und Testdatensatz aufgeteilt. Der Trainingsdatensatz enthält 75\% der Datenpunkte, der Testdatensatz die restlichen 25\%. Da während der Parameteroptimierung die Ergebnisse der Gittersuche mit einer Kreuzvalidierung überprüft werden, werden die Modelle jedoch nicht mit dem vollständigen Trainingsdatensatz trainiert. Es wird eine zehnfache Kreuzvalidierung durchgeführt. Zur Validierung der Modelle im Rahmen der Gittersuche wird also ein fünftel des Trainingsdatensatzes zur Validierung verwendet und nur mit den verbleibenden Trainingdaten können die Modelle trainiert werden. Der Validierungsdatensatz für jede Teilung der Kreuzvalidierung entspricht also \num{7,5}\% von gesamten Datensatz. Die Aufteilung in die genannten Teilgrößen ist für Problemstellungen des maschinellen Lernens üblich. Dabei handelt es sich jedoch lediglich um Erfahrungswerte, die häufig zu brauchbaren Modellen geführt haben. Die Umstände dieses Usecases lässt keine Notwendigkeit die Werte anpassen zu müssen vermuten. Als problematisch ist dagegen die Größe des Rohdatensatzes anzusehen.

Üblicher weise werden bei der Kreuzvalidierung fünf oder zehn Teilungen vorgenommen. Da der Datensatz mit 200 Datenpunkten relativ klein ist, ist es hier sinn voll eine zehnfache Teilung vorzunehmen. So können pro Teilung \SI{90}{\percent} der Trainingdaten verwendet werden. Für den Validierungsfold stehen dann zwar jeweils nur \SI{7,5}{\percent} der Daten zur Verfügung, dies hat aber keine Bedeutung für die Kreuzvalidierung.