\chapter{Methodik}
\label{ch:methodik}
Um eine zustandsbasierte -- und darauf aufbauend eine prädiktive -- Instandhaltung umsetzten zu können, ist es nötig Daten zu gewinnen, die diesen Zustand beschreiben, und ein Model zu erstellen, das diese auswertet. Es folgt eine Beschreibung der Methodik nach der die Ergebnisse aus \cref{ch:modelbewertung} erarbeitet werden. Die Methodik beschränkt sich auf die Entwicklung eines zustandbestimmenden Models. Eine Weiterentwicklung hin zu einem Model mit dem Ausfälle vorhergesagt werden können, war im zeitlichen Rahmen dieser Arbeit nicht möglich. Das erarbeitete Model stellt eine Voraussetzungen für die Weiterentwicklung dar. 
%===============================================================================
\section{Versuchsaufbau}
\label{sec:versuchsaufbau}
Der in \cref{sec:messdaten} beschriebene Datensatz wird mit folgendem Messaufbau erfasst:

An die Türschließanlage ist eine Druckluftzufuhr angeschlossen. Ein Druckregeler regelt den Luftdruck auf ca. \SI{550000}{\pascal} (\SI{80}{psi}). Der Luftstrom wird durch ein 5/2-Wegeventil gesteuert, dass magnetisch betätigt wird. Die Ventilstellung bestimmt die Bewegungsrichtung des Kolbens der Pneumatikzylinders. Zwischen Druckregeler und Wegeventil ist außerdem ein Absperrventil eingebaut. Dieses wird ebenfalls durch einen Elektromagneten betätigt und kappt die Luftzufuhr, wenn das System zum Stillstand gebracht werden soll.

Sämtliche Ventile werden über Relais mit den jeweils nötigen elektrischen Spannungen versorgt. Die Schaltung der Relais -- und damit die Steuerung der Türschließanlage -- erfolgt durch einen Mikrocontroller vom Typ \todo{Modelname rausfinden}. Dieser führt den Programmcode (s. Anhang) zur Versuchsdurchführung aus.  Dazu gehört auch das Auslesen des installierten Beschleunigungssensor und Gyroskops \todo{Bild von montiertem B-Sensor einfügen}. 

Die Position des Beschleunigungssensors ist so gewählt, dass keine konstruktive Änderung an der Türschließanlage vorgenommen werden muss. Abhängig von der Position des Sensors relativ zur Umlenkrolle sind unterschiedliche Messwerte zu erwarten. Da die absoluten Messwerte für die Klassifikation nicht von Bedeutung sind; sondern nur deren Unterschied in Bezug auf die Kategorien; hat die Position des Sensors jedoch keine Einfluss auf die Qualität.

Zur Speicherung der Daten werden diese über eine serielle USB-Schnittstelle an ein angeschlossenes Computersystem übertragen. Der dort, parallel laufende Programmcode decodiert das Signal des Mikrocontrollers und speichert die Daten in einer passend formatierten CSV-Datei ab.

Um vergleichbare Datenpunkte zu erhalten wird nicht das Original der Umlenkrolle verwendet, sondern mit im Lasersinterverfahren hergestellten Nachbildungen. Die Festigkeit des Materials ist für den Versuch ausreichend. Nach dem Versuch wurden bei einer Sichtprüfung keine plastischen Verformungen festgestellt. Eine der Nachbildungen wurde Rillen versehen, die längst der Bohrung verlaufen \todo{Bild eifügen von CAD model}. Die Rillen simulieren Materialausbrüche als Folge von Pittings. Insgesamt weist die so künstlich beschädigte Umlenkrolle drei Rillen auf die um jeweils 40° \todo{wie viel Grad sind es?} zueinander verschoben sind. Mit verbauter intakter bzw. beschädigter Umlenkrolle werden jeweils 100 Datenpunkte aufgezeichnet.
%===============================================================================
\section{Messwerte und Datenaufbereitung}
\label{sec:messdaten}
Der Datensatz weißt \num{1441} Merkmale auf. Je \num{240} davon bilden eine Zeitreihe einer der Messwerte von Beschleunigungssensor bzw. dem Gyroskop. Insgesamt beinhaltet der Datensatz folgende Messwerte (Achsenrichtungen beziehen sich auf den Beschleunigungssensor):
\begin{itemize}
	\item Beschleunigung in positive X-Richtung
	\item Beschleunigung in positive Y-Richtung
	\item Beschleunigung in positive Z-Richtung
	\item Rotationgeschwindigkeiten um X-Achse
	\item Rotationgeschwindigkeiten um Y-Achse
	\item Rotationgeschwindigkeiten um Z-Achse
	\item Zykluszeit: Dauer von einem Öffnungs- und Schließvorgang (inkl. Laufzeitpause das Programmcodes)
\end{itemize}

Die Messgrößen der Beschleunigungen und der Rotationgeschwindigkeiten wurden ausgewählt, da sie das Schwingungsprofil der Anlage beschreiben. Es wird erwartet, dass sich dieses mit dem Grad der Beschädigung der Umlenkrollen ändert. Es kann also erwartet werden, dass die gewählten Messgrößen aussagekräftig über den Zustand der Umlenkrollen sind. Voraussetzung ist das, dass eine andere Ursache für die Änderung des Vibrationsprofils nicht in Frage kommt. Diese Voraussetzung ist hier geben, weil die Umlenkrolle die einzige Variable im Versuchsaufbau ist.

Für die Modelentwicklung ist es sinnvoll die Rohdaten in einem beschreibenden Datensatz zusammen zu fassen. Die erstellten Modelle basieren auf Entscheidungsbäumen mit maximal sechs Knoten je Ast (vgl. \cref{sec:modelauswahl} bzw. \cref{sec:modelierung}). Das bedeutet, dass jeder Entscheidungsbaum nur einen sehr kleinen Anteil der Merkmale des Rohdatensatzes verwenden kann. Dies kann eine ungewünschte negative Auswirkung auf die Entwicklung des Models haben. Es besteht die Möglichkeit, dass ein Model nur Merkmale berücksichtigt, die zu dem selben Messwert gehören, weil diese zufällig eine höhe Aussagekraft für den Datensatz haben, aber nicht zwangsläufig für die Population gültig sind. Informationsgehalt der anderen Messwerte geht so verloren. Mit einem Datensatz, der die Informationen der Zeitreihen in statistischen Parametern zusammenfasst, kann eine größerer Anteil dieser Merkmale verwendet werden und so mehr Informationen des Rohdatensatzes genutzt werden. Die Entscheidungsbäume der erstellten Modelle besitzen maximal \num{32} Knoten (s.~\cref{sec:modelierung}). Sie können alle Merkmale des beschreibenden Datensatzes nutzen, der insgesamt über \num{25} Merkmale verfügt.

Aus dem genannten Grund wird ein beschreibender Datensatz aus den Rohdaten abgeleitet. Der Datensatz beschreibt die Messungen anhand folgender Parameter (je Messgröße).
\begin{itemize}
	\item Minimalwert
	\item Maximalwert
	\item Median
	\item Standardabweichung
	\item Zykluszeit
\end{itemize}
%===============================================================================
\section{Modelauswahl}
\label{sec:modelauswahl}
Für die Modelentwicklung können aus Zeitgründen nicht alle in Frage kommenden Modeltypen berücksichtigt werden. Aus der Menge der Klassifikationsmodelle kann eine sinnvolle Vorauswahl getroffen werden. So kann die Anzahl der Modelle, die tatsächlich entwickelt und verglichen werden müssen, auf ein handhabbares Maß reduziert werden.

Die Vorauswahl geeigneter Modeltypen richtet sich nach folgenden Anforderungen. Die Anforderungen sind von den Erfolgskriterien Komplexität und Modelqualität des Usecases abgeleitet (vgl.~\cref{sec:erfolgskriterien_usecase}).

\begin{itemize}
    \item Für den vorhandenen Datensatz muss eine hohe Modelqualität erwartet werden können. Die Modelqualität wird für den Usecase durch die Sensitivität und Relevanz der Klassifikation bestimmt.
    \item Das Model muss prinzipiell nachvollziehbar sein. D.h. es muss möglich sein die Ergebnisse des Modell auf Logikfehler hin untersuchen zu können, um zufällige Abweichungen der Ergebnisse identifizieren zu können. Gleichzeitig muss die Komplexität quantifizierbar sein, damit ein Vergleich möglich ist.
\end{itemize}

Unter den genannten Voraussetzungen kommen diese Modeltypen in Frage:
\begin{itemize}
    \item Logistic Regression
    \item Entscheidungsbäume
    \item k-nearest neighbors
    \item Naive Bayes
\end{itemize}

Modeltypen, die von ihrem Funktionsprinzip her keine Beurteilung des Entscheidungsprozesses zulassen, sind erfüllen die Grundvorsetzung für das Komplexitäts-Kriterium nicht. \enquote{Support Vector Machines} und \enquote{neuronale Netze} scheiden daher aus.

Für die Modelentwicklung werden nur Modelle verwendet, die auf Entscheidungsbäumen basieren. Gegenüber den anderen Modeltypen sind sie günstig zu visualisieren und lassen auf dicht besetzten Datensätzen gute Modelqualitäten erwarten. Außerdem ist eine weniger aufwendige Aufbereitung der Daten nötig, weil die Daten nicht skaliert werden müssen~\cite[S.~84--85]{Muller.2017}

Die Modelentwicklung wird auf die Vorauswahl hin weiter auf die drei Algorithmen \textit{einfacher Entscheidungsbaum}, \textit{Random Forest} und \textit{Gradient Boosted Trees} begrenzte (s.~\cref{sec:algorithmen_mit_entscheidungsbaum})
%===============================================================================
\section{Bewertungskriterien}
\label{sec:bewertungskriterien}
Aus der Vorauswahl an Algorithmen soll das Model bestimmt werden, das die Anforderungen an den Usecase (s.~\cref{sec:erfolgskriterien_usecase}) best möglich erfüllt. Es ist deswegen notwendig den Erfüllungsgrad der Anforderungen durch die einzelnen Modelle quantifizieren zu können. Die Bewertung der Modelle erfolgt in zwei Schritten.

Erstens werden Bewertungskriterien definiert, die verschiedenen Modeleigenschaften einen konkreten Wert zwischen \num{0} und \num{1} zuweisen. Im zweiten Schritt werden die Bewertungskriterien zu einer Präferenzfunktion zusammengefasst. Die Präferenzfunktion addiert die gewichteten Kriterienwerte auf. So wird für ein Model ein Gesamtscore ermittelt, der ebenfalls Werte zwischen \num{0} und \num{1} annehmen kann. Ein Wert von \num{1} entspricht einer idealen Erfüllung der Anforderungen.

\cref{tab:bewertungskriterien_fuer_praeferenzfunktion} zeigt die Bewertungskriterien und die zugeordneten Kriterienwerte. Die Gewichtungen der Kriterien wurden durch einen Paarvergleich bestimmt; siehe \cref{tab:paarvergleich}. Eine \num{1} bedeutet dabei, dass das Kriterium weniger wichtig ist; eine \num{2}, dass es wichtiger ist als das Vergleichskriterium.

Die Komplexität bezieht sich auf die Anforderung, dass das Model nachvollziehbar sein muss. Für die Komplexität gilt, dass sie so gering wie möglich sein sollte und dennoch die Erfolgskriterien des Usecases (\cref{sec:erfolgskriterien_usecase}) erreicht werden können. Quantifiziert wird die Komplexität durch die Anzahl der Baumebenen (Tiefe) und die Anzahl der Bäume, die zusammen ein Model bilden.

Die Sensitivität beschreibt wie viele Datenpunkte der positiven Kategorie als solche erkannt wurden. Im Kontext der vorausschauende Instandhaltung bedeutet die Sensitivität welcher Anteil an bevorstehenden Ausfällen vermieden werden kann. Ihr Betrag sollte also möglichst groß sein. Zwar ist nicht bekannt wie viele Ausfälle durch präventive Instandhaltung verhindert werden könnten, aber es wird die Bedingung gestellt, dass mindestens \SI{95}{\percent} aller Ausfälle richtig vorhergesagt werden können. In der Regel ziehen ungeplante Ausfälle deutlich höher Kosten nach sich als Fehlalarme.

Die Relevanz beschreibt wie viele Datenpunkte tatsächlich der positiven Kategorie angehören von denen die als solche eingestuft worden sind. Eine niedrige Relevanz bedeutet demnach eine große Anzahl Fehlalarme. Da Fehlalarme jedoch verhältnismäßig kleine Kosten -- im Vergleich zu ungeplanten Ausfällen -- nach sich ziehen, kann auch eine niedrige Relevanz toleriert werden.

\begin{table}[ht]
	\raggedright
	\begin{tabularx}{\textwidth}{ | l | l | c | X|}
		\hline
		\rowcolor{gray}
		Kriterium & \thead{Wertezuordnung:\\Kriteriumswert\\ $\rightarrow$ Erfüllungsgrad} & Gewichtung & Bemerkungen \\ 
		\hline
		\multirow{5}{*}{\thead{Baumtiefe\\(Komplexität)}} & \num{1} $\rightarrow$ \num{1} & \multirow{5}{*}{\num{0.165}} & \multirow{5}{*}{Insgesamt wird die Komplexität mit \num{0,22} gewichtet. Da die Komplexität exponentiell mit der Baumtiefe steigt und linear mit der Baumanzahl wurde entschieden, dass die Baumtiefe \SI{75}{\percent} der Komplexität ausmacht; also $0.22*0.75=0,165$. Die restlichen \SI{0.055}{\percent} entfälle auf die Baumanzahl}\\
		& \num{2} $\rightarrow$ \num{0,75} &&\\
		& \num{3} $\rightarrow$ \num{0,5} &&\\
		& \num{4} $\rightarrow$ \num{0,25} &&\\
		& $>=5$ $\rightarrow$ \num{0} &&\\
		\hline
		\multirow{5}{*}{\thead{Baumanzahl\\(Komplexität)}} & \num{1} $\rightarrow$ \num{1} & \multirow{5}{*}{\num{0.05}} & \multirow{5}{*}{s. Baumtiefe}\\ 
		& \num{2} $\rightarrow$ \num{0,75} &&\\
		& \num{3} $\rightarrow$ \num{0,5} &&\\
		& \num{4} $\rightarrow$ \num{0,25} &&\\
		& $>=5$ $\rightarrow$ \num{0} &&\\
		\hline
		Sensitivität & 1,0C & \num{0.44} & Je höher die Sensitivität ist, desto weniger falsch negative Vorhersagen werden getroffen. Für den PDM-Usecase bedeutet es, dass mehr Instandhaltungsarbeiten geplant werden können. \\
		\hline
        Relevanz & xx & \num{0.33} & Eine hohe Relevanz bedeutet, dass wenige falsch positive Vorhersagen getroffen werden. Entsprechend niedrig fällt die Anzahl unnötiger Inspektionen für den PDM-Usecase aus.\\
		\hline
	\end{tabularx}
	\caption{Bewertungskriterien für Präferenzfunktion}%muss unten sein, sonst caption über Tab
	\label{tab:bewertungskriterien_fuer_praeferenzfunktion}	%zum referenzieren
\end{table}

\begin{table}[h]
	\begin{tabularx}{\textwidth}{|l|ccc|c|r|}
		\hline
		& \rotatebox{90}{Komplexität} & \rotatebox{90}{Sensitivität} & \rotatebox{90}{Relevanz} & \rotatebox{90}{Summe} & Gewicht\\
		\hline
		Komplexität & -- & 1 & 1 & 2 & 22\%\\
		Sensitivität & 2 & -- & 2 & 4 & 44\%\\
		Relevanz & 2 & 1 & -- & 3 & 33\%\\
		\hline
		\hline
		Gesamt & \multicolumn{2}{c}{} & & 9 & $\approx$ 100\%\\
		\hline
	\end{tabularx}
	\caption{Paarvergleich zur Bestimmung der Gewichtungen der Bewertungskriterien}
	\label{tab:paarvergleich}
\end{table}

Mit den Werten aus \cref{tab:bewertungskriterien_fuer_praeferenzfunktion} wird die Präferenzfunktion aufgestellt:

\begin{equation*}
	\text{Gesamtscore}=0.165\cdot t
	0.055\cdot a+0.44\cdot s+0.33\cdot r
	\label{eq:praeferenzfunktion}
\end{equation*}

Dabei ist $t$ der Wert der dem Bewertungskriterium \textit{Tiefe} zugeordnet wird. Entsprechend ist $a$ der Wert zur Baumanzahl, $s$ der Wert zur Sensitivität und $r$ der Wert zur Relevanz (vgl. \cref{tab:bewertungskriterien_fuer_praeferenzfunktion}).
%===============================================================================
\section{Modelierung}
\label{sec:modelierung}
WIE WERDEN DIE MODELE ERSTELLT? WIESO IST DIE PARAMETERSTUDIE IN DER FORM SINNVOLL? WELCHE EIGENSCHAFTEN DER MODELLE WERDEN BEI DER MODELLIERUNG DER MODELLE BERÜCKSICHTIGT? 

Ziel dieser Arbeit ist ein maschinelles Lernmodell zu bestimmen, dass möglichst gut den Anforderungen des beschriebenen PDM-Usecases gerecht wird. Um das Spektrum möglicher Modelle im Vorfeld einzugrenzen, wurden bereits gewisse Modeltypen ausgeschlossen, da diese nicht den Grundanforderungen an den Usecase genügen. Die Auswahlmöglichkeiten wurden aus Modelle beschränkt die auf Entscheidungsbäumen basieren \todo{Verweis auf Modelauswahl einfügen}.

Konkret werden Modelle der folgenden Typen modelliert werden und aus diesen das beste für den Usecase ausgewählt.
\begin{itemize}
    \item einfacher Entscheidungsbaum
    \item Random Forest
    \item Gradient Boosted Trees
\end{itemize}

Für die Modellbewertung ist es entscheidend, dass die einzelnen Modelle Charakteristika aufweisen, die vergleichbar sind. Eigenschaften, die alle drei Typen gemeinsam haben sind u.a. die Anzahl der Bäume und die Tiefe der Bäume. Für den Usecase, um den es sich handelt, spielt die Komplexität der Modelle eine Rolle. Diese wird durch die Baumanzahl und deren Tiefe eindeutig festgelegt. Die anderen Bewertungskriterien sind bei Klassifikatoren grundsätzlich vergleichbar (Relevanz, Signifiganz, etc.).
Die gewählten Modelltypen können also sinnvoller Weise miteinander verglichen werden. 

Ehe die trainierten Modelle verglichen werden können, ist es notwendig die Modelle zu optimieren. Die Qualität eines Modell ist nämlich nicht nur von dem zugrundeliegenden Algorithmus abhangig, sondern auch von den eingestellten Parametern. Erst wenn für jeden Modelltyp die optimalen Parameter bestimmt sind kann also eine Aussage über die Überlegenheit eines Modelltyps getroffen werden.

Die Modelle wurden durch zwei Iterationen an Gittersuchen optimiert. Während der ersten Iteration wurde ein weiterer Wertebereich durch gröbere Parameterschritte abgedeckt als in der zweiten Iteration. Um eine hinreichend gute Annäherung zu erreichen, wurden für bei der zweiten Iteration neuen Wertebereiche gewählt, die auf der Annäherungen der ersten Iteration beruhen.



Laut Müller \todo{Quelle einfügen S 79} ist es für einfache Entscheidungsbäume bereits in der Regel ausreichend einen Parameter für Präpruning zu setzen, um Overfitting zu verhindern. Entsprechend wurde sich für die Optimierung des einfachen Entscheidungsbaum-Klassifikators auf die maximale Tiefe beschränkt. 

Weiter sind nach Müller die wichtigsten Parameter für Random Forest die Anzahl der Klassifikatoren, die Anzahl maximal zu verwendender Merkmale und ein Parameter zum Präpruning. Für das Präpruning wird auch hier eine begrenzte Baumtiefe verwendet, damit die Komplexität der Modelle verglichen werden kann (s.o.). 
Müller empfiehlt weiterhin den Standardwert für die Maximalanzahl an Merkmalen zu verwenden. (S 85) Da die Umstände des Usecase hier keine Ausnahmesituation vermuten lassen, wird dieser Parameter nicht in die Modelloptimierung mit einbezogen.
Schließlich wird für die Anzahl der Klassifikatoren in einem Bereich von 20 bis 120 das Optimum bestimmt.

Für die Gradient Boosted Trees muss ebenfalls die Baumtiefe für das gleiche Spektrum optimiert werden wie für die anderen Modeltypen, um dieses Kriterum vergleichen zu können. Darüber hinaus sind laut Müller \todo{Zitat einfügen S88} die Anzahl der Bäume und die Lernrate für diesen Modeltype von besonderer Bedeutung. Davon abgesehen muss die Baumanzahl für den Vergleich eingegrenzt werden. Es ist wichtig beide Parametre parallel zu betrachten, weil diese von einander abhängig sind \todo{Zitat Müller einfügen S88}

Um die Modelle während der Gittersuche zu evaluieren, um die beste Kombination an Parametern bestimmen zu können, wird eine fünffache Kreuzvalidierung verwendet. Vor dem Hintergrund, dass der Datensatz perfekt balanziert ist und eine zufällige Auswahl der Datenpunkte bei der Aufteilung in Trainings-, Validierungs- und Testdatensatz vorgenommen wurde, dient die Kreuzvalidierung nur dazu zusätzliche Sicherheit bei der Evaluation zu gewährleisten.

Als Scoringparameter der Gittersuche wurde die Sensitivität gewählt. Diese hat in der Präferenzfunktion das größte Gewicht. 

Die Parameterstudie hat für den GBT eine Baumanzahl von 95 ergeben. Das Model war damit sehr komplex verglichen mit den anderen. Gleichzeitig war die Sensitivität bei 1. Daher wird vermutet, dass Overfitting vorlag. Um dem entgegen zu wurde der Wertebereich der Bäumeanzahl auf 10 bis 30 reduziert. Das neue GBT-Model war mit 26 Bäumen deutlich simpler und erzielte dennoch zufrieden stellende, aber nicht länger perfekte Scores. Es könnte daraus geschlossen werden, dass das ursprüngliche Model tatsächlich Overfitting aufwies.
%===============================================================================