\chapter{Methodik}
\label{ch:methodik}

\section{Modelauswahl}
\label{sec:modelauswahl}

Grundsätzlich eignet sich jedes Klassifikatormodel für die vorliegende Aufgabe. Darüber hinaus geben sich aus der Natur der Problemstellung weitere Anforderungen an die Modelle:

\begin{itemize}
    \item Das Model muss die Ergebnisse in Form einer Konfusionmatrix wiedergeben können, damit Sensitivität und Relevanz bestimmt werden können. \todo{Prüfe: geben nicht eh alle Modelle eine Konfusionsmatrix aus?} Diese werden für die Bewertung der Modelle benötigt; s. \todo{Füge Verweis auf Präferenzfunktion ein}
    \item Das Model muss prinzipiell nachvollziehbar sein. D.h. das Sachverständige in der Lage seinen müssen die Ergebnisse des Modell auf Logikfehler hin untersuchen zu können. \todo{Verweis auf diesen Punkt, wenn begründet wird warum NN und SVM´s rausfliegen}
\end{itemize}

Unter den genannten Voraussetzungen kommen Modelle folgender Arten in Frage:
\begin{itemize}
    \item Logistic Regression
    \item Bäume
    \item k-nearest neighbors
    \item Naive Bayes
\end{itemize}

Da der Datensatz im Vergleich zu anderen Machinelearningproblemen wenige Features beinhaltet \todo{spezifizieren wie viele Features} können Modelle die auf Entscheidungsbäumen basieren gut dargestellt werden. Außerdem lassen sich die Entscheidungen in den einzelnen Blättern genau nachvollziehen und bewerten. Aus diesen beiden Gründen werden für die Modellentwicklung zunächst nur Entscheidungsbäume herangezogen. 

\section{Bewertungskriterien}
\label{sec:bewertungskriterien}

Tabelle \todo{Verweis auf Tabelle einfügen} zeigt die einzelnen Bewertungskriterien der Modelle. Im Abschnitt \todo{Verweis auf abschnitt Präferenzfunktion} werden diese zu einem einzelnen Wert zusammengefasst. 

An dieser Stelle sollen die Bewertungskriterien genauer beschrieben, ihre Wertefunktionen und Limits begründet und ihre Bedeutung für die Modelqualität dargestellt werden.

Die Komplexität bezieht sich auf die Anforderung, dass das Model nachvollziehbar sein muss. Wie in Abschnitt \cref{sec:modelauswahl} bereits erwähnt darf das Model von seiner Natur her keine Blackbox sein, um eine Nachvollziehbarkeit grundsätzlich möglich zu machen. Für die Komplexität gilt, dass sie so gering wie möglich sein sollte und dennoch die Dataminingerfolgskriterien erreicht werden können. Quantifiziert wird die Komplexität anhand der von Model verwendeten Merkmale. 

Die Sensitivität beschreibt wie viele Datenpunkte der positiven Kategorie als solche erkannt wurden. Im Kontext der vorausschauende Instandhaltung bedeutet die Sensitivität welcher Anteil an bevorstehenden Ausfällen vermieden werden kann. Ihr Betrag sollte also möglichst groß sein. Zwar ist nicht bekannt wie viele Ausfälle durch präventive Instandhaltung verhindert werden könnten, aber es wird die Bedingung gestellt, dass mindestens 95\% aller Ausfälle richtig vorhergesagt werden können. Diese Wahl ist sinnvoll, weil ungeplante Ausfälle in der Regel deutlich höher Kosten nach sich ziehen, als Fehlalarme.

Die Relevanz beschreibt wie viele Datenpunkte tatsächlich der positven Kategorie angehören von denen die als solche eingestuft worden sind. Eine niedrige Relevanz bedeutet demnach eine große Anzahl Fehlalarme. Da Fehlalarme jedoch verhältnismäßig kleine Kosten -- im Vergleich zu ungeplanten Ausfällen -- nach sich ziehen, kann auch eine niedrige Relevanz toleriert werden.


\section{Präferenzfunktion}
\label{sec:präferenzfunktion}

Um die Modelle einfach mit ein ander vergleichen zu können, wird eine Präferenzfunktion aufgestellt. Diese erlaubt es einem Modell anhand relevanter Kriterien einen \textit{Kosten-Nutzen-Score} zuzuweisen. Die Präferenzfunktion lautet:
\begin{center}
    Nutzenscore=\num{0,22}$\bullet$ Komplexität + \num{0,44}$\bullet$ Sensitivität + \num{0,33} $\bullet$ Relevanz
\end{center}

Die einzelnen Variablen der Funktion stellen die Bewertungskriterien dar. Ihnen wird jeweils ein Wert zwischen 0 und 1 zugewiesen; entsprechend \todo{Tabelle für Bewertungskriterien verweisen}.

Die Bewertungskriterien sind mit einem Gewichtungsfaktor versehen. Die Gewichtungen spiegeln die Ergebnisse eines Paarvergleichs der Kriterien wieder. \todo{Paarvergleichstabelle erstellen und in Anhang einfügen}

Der Nutzenscore kann einen beliebigen Wert zwischen 0 und 1 annehmen. Das Model, das den höchsten Nutzenscore erzielt, ist für den potentiellen PDM-Anwendungsfall zu bevorzugen.

Tabelle \todo{Refernez einfügen} zeigt die gewählt Zuordnung der Werte für die Summanden der Präferenzfunktion sowie derer Gewichtungen. Die Gewichtungen wurden durch einen Paarvergleich ermittelt.

\begin{table}[ht]
	\raggedright
	\begin{tabularx}{\textwidth}{ | l | l | l | X|}
		\hline
		% \rowcolor{gray}
		Kriterium & Wertezuordnung: Kriteriumswert $\rightarrow$ Erfüllungsgrad & Gewichtung & Bemerkungen \\ 
		\hline
		% \multirow{5}{*}{Baumtiefe (Komplexität)} & \num{1} \rightarrow \num{1} & \num{2} \rightarrow \num{0.75} & \num{3} \rightarrow \num{0,5} & \num{4} \rightarrow \num{0,25} $>=5$ \rightarrow \num{0} & \multirow{5}{*}{\num{0,165}} & \multirow{5}{*}{Insgesamt wird die Komplexität mit \num{0,22} gewichtet. Da die Komplexität exponentiell mit der Baumtiefe steigt und linear mit der Baumanzahl wurde entschieden, dass die Baumtiefe \SI{75}{\percent} der Komplexität ausmacht; also $0.22*0.75=0,165$. Die restlichen \SI{0.055}{\percent} entfälle auf die Baumanzahl}\\ 
		\hline
		Baumanzahl (Komplexität) & 9C & \num{0.05} & s. Baumtiefe\\ 
		\hline
		Sensitivität & 10C & \num{0.44} & Je höher die Sensitivität ist, desto weniger falsch negative Vorhersagen werden getroffen. Für den PDM-Usecase bedeutet es, dass mehr Instandhaltungsarbeiten geplant werden können. \\
		\hline
        Relevanz & xx & \num{0.33} & Eine hohe Relevanz bedeutet, dass wenige falsch positive Vorhersagen getroffen werden. Entsprechend niedrig fällt die Anzahl unnötiger Inspektionen für den PDM-Usecase aus.\\
	\end{tabularx}
	\caption{Metriken für Präferenzfunktion}%muss unten sein, sonst caption über Tab
	\label{tab:metriken_praeferenzfunktion}	%zum referenzieren
\end{table}