\chapter{Modelierung}
\label{ch:modelierung}

Ziel dieser Arbeit ist ein maschinelles Lernmodell zu bestimmen, dass möglichst gut den Anforderungen des beschriebenen PDM-Usecases gerecht wird. Um das Spektrum möglicher Modelle im Vorfeld einzugrenzen, wurden bereits gewisse Modeltypen ausgeschlossen, da diese nicht den Grundanforderungen an den Usecase genügen. Die Auswahlmöglichkeiten wurden aus Modelle beschränkt die auf Entscheidungsbäumen basieren \todo{Verweis auf Modelauswahl einfügen}.

Konkret werden Modelle der folgenden Typen modelliert werden und aus diesen das beste für den Usecase ausgewählt.
\begin{itemize}
    \item einfacher Entscheidungsbaum
    \item Random Forest
    \item Gradient Boosted Trees
\end{itemize}

Für die Modellbewertung ist es entscheidend, dass die einzelnen Modelle Charakteristika aufweisen, die vergleichbar sind. Eigenschaften, die alle drei Typen gemeinsam haben sind u.a. die Anzahl der Bäume und die Tiefe der Bäume. Für den Usecase, um den es sich handelt, spielt die Komplexität der Modelle eine Rolle. Diese wird durch die Baumanzahl und deren Tiefe eindeutig festgelegt. Die anderen Bewertungskriterien sind bei Klassifikatoren grundsätzlich vergleichbar (Relevanz, Signifiganz, etc.).
Die gewählten Modelltypen können also sinnvoller Weise miteinander verglichen werden. 

Ehe die trainierten Modelle verglichen werden können, ist es notwendig die Modelle zu optimieren. Die Qualität eines Modell ist nämlich nicht nur von dem zugrundeliegenden Algorithmus abhangig, sondern auch von den eingestellten Parametern. Erst wenn für jeden Modelltyp die optimalen Parameter bestimmt sind kann also eine Aussage über die Überlegenheit eines Modelltyps getroffen werden.

Die Modelle wurden durch zwei Iterationen an Gittersuchen optimiert. Während der ersten Iteration wurde ein weiterer Wertebereich durch gröbere Parameterschritte abgedeckt als in der zweiten Iteration. Um eine hinreichend gute Annäherung zu erreichen, wurden für bei der zweiten Iteration neuen Wertebereiche gewählt, die auf der Annäherungen der ersten Iteration beruhen.



Laut Müller \todo{Quelle einfügen S 79} ist es für einfache Entscheidungsbäume bereits in der Regel ausreichend einen Parameter für Präpruning zu setzen, um Overfitting zu verhindern. Entsprechend wurde sich für die Optimierung des einfachen Entscheidungsbaum-Klassifikators auf die maximale Tiefe beschränkt. 

Weiter sind nach Müller die wichtigsten Parameter für Random Forest die Anzahl der Klassifikatoren, die Anzahl maximal zu verwendender Merkmale und ein Parameter zum Präpruning. Für das Präpruning wird auch hier eine begrenzte Baumtiefe verwendet, damit die Komplexität der Modelle verglichen werden kann (s.o.). 
Müller empfiehlt weiterhin den Standardwert für die Maximalanzahl an Merkmalen zu verwenden. (S 85) Da die Umstände des Usecase hier keine Ausnahmesituation vermuten lassen, wird dieser Parameter nicht in die Modelloptimierung mit einbezogen.
Schließlich wird für die Anzahl der Klassifikatoren in einem Bereich von 20 bis 120 das Optimum bestimmt.

Für die Gradient Boosted Trees muss ebenfalls die Baumtiefe für das gleiche Spektrum optimiert werden wie für die anderen Modeltypen, um dieses Kriterum vergleichen zu können. Darüber hinaus sind laut Müller \todo{Zitat einfügen S88} die Anzahl der Bäume und die Lernrate für diesen Modeltype von besonderer Bedeutung. Davon abgesehen muss die Baumanzahl für den Vergleich eingegrenzt werden. Es ist wichtig beide Parametre parallel zu betrachten, weil diese von einander abhängig sind \todo{Zitat Müller einfügen S88}

Um die Modelle während der Gittersuche zu evaluieren, um die beste Kombination an Parametern bestimmen zu können, wird eine fünffache Kreuzvalidierung verwendet. Vor dem Hintergrund, dass der Datensatz perfekt balanziert ist und eine zufällige Auswahl der Datenpunkte bei der Aufteilung in Trainings-, Validierungs- und Testdatensatz vorgenommen wurde, dient die Kreuzvalidierung nur dazu zusätzliche Sicherheit bei der Evaluation zu gewährleisten.

Als Scoringparameter der Gittersuche wurde die Sensitivität gewählt. Diese hat in der Präferenzfunktion das größte Gewicht. 

Die Parameterstudie hat für den GBT eine Baumanzahl von 95 ergeben. Das Model war damit sehr komplex verglichen mit den anderen. Gleichzeitig war die Sensitivität bei 1. Daher wird vermutet, dass Overfitting vorlag. Um dem entgegen zu wurde der Wertebereich der Bäumeanzahl auf 10 bis 30 reduziert. Das neue GBT-Model war mit 26 Bäumen deutlich simpler und erzielte dennoch zufrieden stellende, aber nicht länger perfekte Scores. Es könnte daraus geschlossen werden, dass das ursprüngliche Model tatsächlich Overfitting aufwies.